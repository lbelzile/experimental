{
  "hash": "4a1cd4b4d1b9302bc07c5f59f7ff75fd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"MATH 80667A - Week 3\"\nauthor: \"LÃ©o Belzile\"\nformat: html\neval: true\necho: true\nmessage: false\nwarning: false\ncode-tools:\n      source: true\n      toggle: false\n      caption: \"Download Quarto file\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\n\ndata(arithmetic, package = \"hecedsm\")\n## #Fit one way analysis of variance\nmodel <- aov(data = arithmetic,\n            formula = score ~ group)\nanova(model) #print anova table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: score\n          Df Sum Sq Mean Sq F value     Pr(>F)    \ngroup      4    723   180.7    15.3 0.00000012 ***\nResiduals 40    473    11.8                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Compute p-value by hand\npf(15.27,\n   df1 = 4,\n   df2 = 40,\n   lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.000000116\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# How reliable is this F benchmark? To see this, we generate data from a normal\n# distribution with the same mean and variance as the original data\nmu <- mean(arithmetic$score)\nsigma <- sd(arithmetic$score)\nB <- 10000L # Number of replications\nset.seed(1234) # fix the dice to get reproducible results\npval <- test <- numeric(B) # container to store results\nfor(b in 1:B){\n  # Generate fake results (assuming common average) from normal distribution\n  fakescore <- rnorm(n = 45, mean = mu, sd = sigma)\n  # For each fake dataset, compute ANOVA F-test statistic and p-value\n  out <- anova(aov(fakescore ~ arithmetic$group))\n  test[b] <- broom::tidy(out)$statistic[1]\n  pval[b] <- broom::tidy(out)$p.value[1]\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Look at what happens under the null\n# Histogram (suitably rescaled) matches F(4, 40) benchmark null distribution\nggplot(data = data.frame(test),\n       mapping = aes(x = test)) +\n  geom_histogram(mapping = aes(y = after_stat(density)),\n                 bins = 100L,\n                 boundary = 0) +\n  stat_function(fun = df, args = list(df1 = 4, df2 = 40)) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Histogram of bootstrap null distribution against $F(4, 40)$ large-sample approximation.](MATH80667A-03-content_files/figure-html/fig-histogram-benchmark-1.png){#fig-histogram-benchmark width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# When there are no difference in mean and the variance are equal\n# i.e., when all assumptions are met, then p-values should be uniformly\n# distributed, meaning any number between [0,1] is equally likely\nggplot(data = data.frame(pval),\n       mapping = aes(x = pval, \n                     y = after_stat(count / sum(count)))) +\n  geom_histogram(breaks = seq(0, 1, by = 0.1)) +\n  scale_y_continuous(labels = scales::percent, \n                     limits = c(0, NA), \n                     expand = expansion()) + \n  scale_x_continuous(breaks = seq(0, 1, by = 0.25),\n                     labels = c(\"0\",\"0.25\",\"0.5\",\"0.75\",\"1\"),\n                     limits = c(0, 1), expand = expansion()) +\n  labs(y = \"percentage per bin\", x = \"p-value\") + \n  theme_classic()\n```\n\n::: {.cell-output-display}\n![Histogram of $p$-values from the $F$ test.](MATH80667A-03-content_files/figure-html/fig-histogram-pvalues-1.png){#fig-histogram-pvalues width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Two-sample t-test (equal variance) and one-way ANOVA\n# are equivalent for comparison of two groups\ndata(\"BJF14_S1\", package = \"hecedsm\")\nanova(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: score\n          Df Sum Sq Mean Sq F value     Pr(>F)    \ngroup      4    723   180.7    15.3 0.00000012 ***\nResiduals 40    473    11.8                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nt.test(pain ~ condition, data = BJF14_S1, var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTwo Sample t-test\n\ndata:  pain by condition\nt = -10, df = 52, p-value = 0.00000000000003\nalternative hypothesis: true difference in means between group Control and group Pain is not equal to 0\n95 percent confidence interval:\n -5.26 -3.56\nsample estimates:\nmean in group Control    mean in group Pain \n                 1.67                  6.07 \n```\n\n\n:::\n\n```{.r .cell-code}\n## Tests for equality of variance are simply analysis of variance\n## models with different data\ncar::leveneTest(model, center = median)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  4    1.21   0.32\n      40               \n```\n\n\n:::\n\n```{.r .cell-code}\n# Brown-Forsythe by default, which centers by median\n# replace 'center=median' by 'center=mean' to get Levene's test\n\nmeds <- arithmetic |>\n  group_by(group) |>\n  summarize(med = median(score)) # replace by mean to get the result for leveneTest\n# Compute absolute difference between response and group median\narithmetic$std <- abs(arithmetic$score - rep(meds$med, each = 9))\n# Compute F-test statistic for analysis of variance with the 'new data'\nanova(aov(std ~ group, data = arithmetic))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: std\n          Df Sum Sq Mean Sq F value Pr(>F)\ngroup      4   19.4    4.86    1.21   0.32\nResiduals 40  160.9    4.02               \n```\n\n\n:::\n:::\n\n::: {#tbl-groupmeans .cell tbl-cap='Average score on arithmetic test per experimental group.'}\n\n```{.r .cell-code}\n# Parametrization of the linear models (see course notes)\n# Here, each group has the same subsample size (balanced)\n# So calculations are more intuitive...\ndata(arithmetic, package = \"hecedsm\")\n# If you fit a one-way ANOVA in R with a linear model via 'lm'\n# The default parametrization is such that the intercept corresponds\n# to the mean of the first level (alphanumerical order) of the factor\n# and other coefficients are difference to that group\narithmetic |>\n  dplyr::group_by(group) |>\n  dplyr::summarize(meanscore = mean(score)) |>\n  knitr::kable(digits = 3, \n               col.names = c(\"group\", \"mean score\"))\n```\n\n::: {.cell-output-display}\n\n\n|group     | mean score|\n|:---------|----------:|\n|control 1 |       19.7|\n|control 2 |       18.3|\n|praise    |       27.4|\n|reprove   |       23.4|\n|ignore    |       16.1|\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova1 <- lm(score ~ group, data = arithmetic)\ncoef(anova1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept) groupcontrol 2    grouppraise   groupreprove    groupignore \n         19.67          -1.33           7.78           3.78          -3.56 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Here, control 1 is baseline (omitted).\n# the difference between intercept and control1 is zero, so no coef. reported\n\n# If we change the 'contrast' argument, we can get the \"DEFAULT\" parametrization\n# of analysis of variance models: sum-to-zero.\n# In that case, the intercept is the global mean and the sum of\n# differences to the mean is zero\nanova2 <- lm(score ~ group,\n   contrasts = list(group = \"contr.sum\"),\n   data = arithmetic)\n# Global mean\nas.numeric(coef(anova2)[\"(Intercept)\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 21\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(arithmetic$score)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 21\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get mean for omitted group (ignore)\n# since the sum of differences to the mean is zero\n# If we add this coefficient to the global mean, we retrieve the\n# subgroup average of 'ignore'\ncoef(anova2)[\"(Intercept)\"] - sum(coef(anova2)[-1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) \n       16.1 \n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}