{
  "hash": "5f8cb5ab04827a4da64aaf491bdf7d55",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"MATH 80667A - Week 13\"\nauthor: \"LÃ©o Belzile\"\nformat: html\neval: true\necho: true\nmessage: false\nwarning: false\ncode-tools:\n      source: true\n      toggle: false\n      caption: \"Download Quarto file\"\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n# Count data\n\n## Example 1 - Duke and Amir (2023), experiment 2\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(coin)\nlibrary(dplyr)\nlibrary(gnm)\ndata(DA23_E2, package = \"hecedsm\")\ntabs <- with(DA23_E2, table(purchased, format))\n# Chi-square test for independence\n(chisq <- chisq.test(tabs))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  tabs\nX-squared = 21, df = 1, p-value = 5e-06\n```\n\n\n:::\n:::\n\n\n\n\n\n## Example 2 - Elliot et al. (2021) multilab\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(MULTI21_D1, package = \"hecedsm\")\n# Create a contingency table\n(contingency <- xtabs( #pool data\n  count ~ age + frequency,\n  data = MULTI21_D1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      frequency\nage    never sometimes usually\n  5yo     53        80      87\n  6yo     28        84     141\n  7yo     19        73     177\n  10yo    14        40     181\n```\n\n\n:::\n\n```{.r .cell-code}\n# No correction to get same result as Poisson regression model\n(chisqtest <- chisq.test(contingency, correct = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test\n\ndata:  contingency\nX-squared = 87, df = 6, p-value <2e-16\n```\n\n\n:::\n:::\n\n::: {#tbl-long-multi .cell tbl-cap='Count data for Elliot et al. (2021) in long format.'}\n\n```{.r .cell-code}\n# Two-way table with (I,J) categories\n# Here, I=4 (age group) and J=3 (frequency)\nMULTI21_D1_long <- MULTI21_D1 |> # pool data by age freq\n  dplyr::group_by(age, frequency) |>\n  dplyr::summarize(total = sum(count)) # aggregate counts\nMULTI21_D1_long |>\n  knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|age  |frequency | total|\n|:----|:---------|-----:|\n|5yo  |never     |    53|\n|5yo  |sometimes |    80|\n|5yo  |usually   |    87|\n|6yo  |never     |    28|\n|6yo  |sometimes |    84|\n|6yo  |usually   |   141|\n|7yo  |never     |    19|\n|7yo  |sometimes |    73|\n|7yo  |usually   |   177|\n|10yo |never     |    14|\n|10yo |sometimes |    40|\n|10yo |usually   |   181|\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Poisson regression\nmod_main <- glm(total ~ age + frequency, # null model, no interaction\n    family = poisson, data = MULTI21_D1_long)\nmod_satur <- glm(total ~ age * frequency, # saturated model\n    family = poisson, data = MULTI21_D1_long)\n# The saturated model returns the observed counts\nisTRUE(all.equal(\n    target = predict(mod_satur, type = \"response\"),\n    current = MULTI21_D1_long$total,\n    check.attributes = FALSE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\n# Likelihood ratio test and score tests\n# There are general families of testing procedures\nanova(mod_main, mod_satur, test = \"LRT\")  # likelihood ratio test, aka deviance stat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel 1: total ~ age + frequency\nModel 2: total ~ age * frequency\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)    \n1         6       85.2                         \n2         0        0.0  6     85.2    3e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(mod_main, mod_satur, test = \"Rao\")  # Rao score test, aka Pearson chi-square test\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel 1: total ~ age + frequency\nModel 2: total ~ age * frequency\n  Resid. Df Resid. Dev Df Deviance  Rao Pr(>Chi)    \n1         6       85.2                              \n2         0        0.0  6     85.2 87.5   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# We can also compute them manually without fitting the saturated model\n# The Pearson chi-square stat is the sum of squared Pearson residuals\nPearsonX2 <- sum(resid(mod_main, type = \"pearson\")^2)\npchisq(q = PearsonX2, df = mod_main$df.residual, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.02e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# The likelihood ratio test is obtained from the deviance\npchisq(q = deviance(mod_main),\n       df = mod_main$df.residual, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.95e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Example 3 - Bertrand and Mullainathan (2004)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(BM04_T2, package = \"hecedsm\")\n# Symmetric model with 6 parameters (3 diag + 3 upper triangular)\nmod_null <- glm(count ~ gnm::Symm(black, white),\n                data = BM04_T2,\n                family = poisson)\n# Compare the two nested models using a likelihood ratio test\npchisq(deviance(mod_null), lower.tail = FALSE,\n       df = mod_null$df.residual) # 9 cells - 6 parameters = 3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.25e-06\n```\n\n\n:::\n\n```{.r .cell-code}\nPearsonX2 <- sum(residuals(mod_null, type = \"pearson\")^2)\npchisq(PearsonX2, df = mod_null$df.residual, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.07e-06\n```\n\n\n:::\n:::\n\n\n\n\n\n# Nonparametric tests\n\n## Example 1 - Brucks and Levav (2022)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(BL22_E, package = \"hecedsm\")\n# Two-sample comparison using Mann-Whitney or Wilcoxon rank-sum test\nmww <- coin::wilcox_test(\n  partner_time ~ cond,\n  data = BL22_E,\n  conf.int = TRUE)\nmww\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAsymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  partner_time by cond (f2f, video)\nZ = -6, p-value = 1e-10\nalternative hypothesis: true mu is not equal to 0\n95 percent confidence interval:\n -50.7 -25.9\nsample estimates:\ndifference in location \n                 -37.8 \n```\n\n\n:::\n\n```{.r .cell-code}\n# The point estimate is Welch's average\n# Values and bounds for confidence intervals are times in seconds\n\n# Compare results with two sample t-test\n(welch_ttest <- t.test(partner_time ~ cond,\n  data = BL22_E,\n  conf.int = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  partner_time by cond\nt = -6, df = 268, p-value = 1e-08\nalternative hypothesis: true difference in means between group f2f and group video is not equal to 0\n95 percent confidence interval:\n -52.9 -26.5\nsample estimates:\n  mean in group f2f mean in group video \n               51.7                91.4 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Example 2 - Brodeur et al. (2021)\n\n\n\n\n\n::: {#tbl-nptest .cell tbl-cap='Effect size for rank-based test.'}\n\n```{.r .cell-code}\ndata(BRLS21_T3, package = \"hecedsm\")\n# Friedman test (more popular, but less powerful than Quade)\nfriedman <- coin::friedman_test(\n  nviolation ~ task | id,\n  data = BRLS21_T3)\nfriedman\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAsymptotic Friedman Test\n\ndata:  nviolation by\n\t task (phone, watch, speaker, texting) \n\t stratified by id\nchi-squared = 19, df = 3, p-value = 3e-04\n```\n\n\n:::\n\n```{.r .cell-code}\n# Quade test\nquade <- coin::quade_test(\n  nviolation ~ task | id,\n  data = BRLS21_T3)\nquade\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAsymptotic Quade Test\n\ndata:  nviolation by\n\t task (phone, watch, speaker, texting) \n\t stratified by id\nchi-squared = 22, df = 3, p-value = 8e-05\n```\n\n\n:::\n\n```{.r .cell-code}\n# Effect size for rank-based tests\neff_size <- effectsize::kendalls_w(\n  x = \"nviolation\",\n  groups = \"task\",\n  blocks = \"id\",\n  data = BRLS21_T3)\neff_size |> \n  knitr::kable(digits = 2,\n               col.names = c(\"Kendall's W\", \"level\", \"lower CL\", \"upper CL\"))\n```\n\n::: {.cell-output-display}\n\n\n| Kendall's W| level| lower CL| upper CL|\n|-----------:|-----:|--------:|--------:|\n|         0.2|  0.95|      0.1|        1|\n\n\n:::\n:::\n\n::: {#tbl-ranks-brodeur .cell tbl-cap='Average rank of the number of road safety violations.'}\n\n```{.r .cell-code}\n# Compute ranks separately for each person\nBRLS21_T3_rank <- BRLS21_T3 |>\n  group_by(id) |>\n  mutate(rank = rank(nviolation)) |>\n  ungroup()\n# Which violation type has the highest rank?\nBRLS21_T3_rank |>\n  group_by(task) |>\n  summarize(mrank = mean(rank)) |>\n  knitr::kable(col.names = c(\"task\",\"mean rank\"))\n```\n\n::: {.cell-output-display}\n\n\n|task    | mean rank|\n|:-------|---------:|\n|phone   |      2.19|\n|watch   |      2.19|\n|speaker |      2.26|\n|texting |      3.35|\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# So texting leads to more violations\n# Transform to wide format - one line per id\nsmartwatch <- tidyr::pivot_wider(\n  data = BRLS21_T3,\n  names_from = task,\n  values_from = nviolation)\n\n# Wilcoxon signed-rank test for all pairwise differences\ntests <- list(\n  wilcoxsign_test(phone ~ watch,\n                  data = smartwatch),\n  wilcoxsign_test(speaker ~ watch,\n                  data = smartwatch),\n  wilcoxsign_test(phone ~ speaker,\n                  data = smartwatch),\n  wilcoxsign_test(phone ~ texting,\n                  data = smartwatch),\n  wilcoxsign_test(texting ~ watch,\n                  data = smartwatch),\n  wilcoxsign_test(texting ~ speaker,\n                  data = smartwatch))\n# Extract p-values of tests\n(pvals <- sapply(tests, pvalue))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.723347 0.767498 0.890557 0.000172 0.000191 0.001344\n```\n\n\n:::\n\n```{.r .cell-code}\n# Adjust for multiple testing using Holm-Bonferroni\np.adjust(pvals, method = \"holm\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.00000 1.00000 1.00000 0.00103 0.00103 0.00537\n```\n\n\n:::\n\n```{.r .cell-code}\n# Only differences with texting are significant (the latter is more distracting)\n```\n:::\n",
    "supporting": [
      "MATH80667A-13-content_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}