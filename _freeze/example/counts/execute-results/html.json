{
  "hash": "36d465af745c2c3412695cd1123ba7e2",
  "result": {
    "markdown": "---\ntitle: \"Count data\"\nlinktitle: \"Count data\"\ntype: docs\neditor_options: \n  chunk_output_type: console\nexecute:\n  echo: true\n  eval: true\n  message: false\n  warning: false\n  cache: true\n  fig-align: 'center'\n  out-width: '80%'\n---\n\n\nMany experiments can have categorical outcomes, which themselves are function of one or several experimental factors. These data can be understood in the same way as other ANOVA models. Such data are often found in papers in the form of contingency tables, giving the total count per factor combination.\n\nThe analogy with analysis of variance doesn't stop there. If we have a two-factor design, the most complicated model is the **saturated** model which has one parameter per cell (since, with count data, we have a single count per cell). The model without the interaction should have the same proportion of observations in both row means and columns, and we can compare the difference in goodness-of-fit arising from dropping the interaction.\n\nIf we have more than two factors, we could pool and aggregate the counts and ignore one dimension to run a series of tests with the two-dimensional tables, amounting to marginalization. Much like in ANOVA, this only makes sense if there is no interaction between the factors. If there is an interaction, we must look at simple effects and fix the level of one factor while comparing the others.\n\n\nThe following section is an introduction to the topic, showcasing examples of tests and their application. It highlights the unifying theme of the course: statistics as summary of evidence, and decision-making in the presence of uncertainty. We use examples drawn from published articles in management sciences.\n\n## Setup\n\nWe consider for simplicity a bivariate contingency table with $I$ rows and $J$ columns and $n$ observations overall; the count in the $(i,j)$ entry of the matrix is $n_{ij}$.\n\n\nPearson's $X^2$ goodness-of-fit test examines discrepancies between  postulated proportions in each cell (with the sum of the probabilities summing to one, $\\sum_{i=1}^I \\sum_{j=1}^J p_{ij0}=1$). The test compare the expected counts $E_{ij}=n \\cdot p_{ij0}$ with the observed counts $O_{ij}=n_{ij}$. As summary of evidence, we take the statistic\n$$ X^2 = \\sum_{i,j} \\frac{(E_{ij}-O_{ij})^2}{E_{ij}},$$\nthe squared difference between expected and observed counts, divided by the expected counts.\n\n\n\nThe contingency table described above represents a two-way factorial design on which we impose $IJ-1$: the one constraint comes from the fact the overall counts must sum to $n$, so one of the numbers is predetermined by others.\n\nRather than specify a full description.\n\nThe model with the two-way interaction has $IJ$ parameters, one for each cell. There, the estimated proportions are simply the observed counts in each cell, divided by the overall sample size. Such model has as many parameters as observations and is said to be **saturated**. The first departure one can consider is thus having different marginal proportions in each row and columns, but no interaction. This hypothesis of **independence** between factors thus compares the model with interaction to the one without.\n\n## Study 1 - Lee and Choi (2019)\n\n@Lee.Choi:2019 study the perception of consumers when faced with inconsistent descriptions of times (when the description doesn't match the image). The dataset `LC19_T2` contains the counts for the expected number of toothbrushes for each combination of image and text.\n\nWe compute the $X^2$ test of independence between \n\na. the text description (`text`) and the expected number of toothbrushes (`expected`).\nb. the image and expected number. \n\n\nIn **R**, the `chisq.test` function will compute the test of independence between rows and columns if you provide a matrix with the cross-counts.\n\n\n::: {.cell hash='counts_cache/html/unnamed-chunk-1_1ecd7ebfcd87f75ef8c23d3e3596ecc9'}\n\n```{.r .cell-code}\ndata(LC19_T2, package = \"hecedsm\")\ncontingency_tab <- \n  with(LC19_T2, \n       xtabs(count ~ text + expected))\n# Score test, chi-square (2) null\nchisq.test(contingency_tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  contingency_tab\nX-squared = 81.071, df = 2, p-value < 2.2e-16\n```\n:::\n:::\n\n\n\nWe can check that our summaries match those reported by the authors, so the results are reproducible. \n\nModels for count data are often obtained by specifying a Poisson distribution for the response and setting factors as explanatories. This makes it perhaps clearer what the $\\chi^2$ test of independence is computing. Note that this isn't the only statistic to compare: below, I fit both the saturated model and the model without interaction and use regular interactions to fit them. The regression model specifies that the response is counts (`family=poisson`).\n\n\n::: {.cell hash='counts_cache/html/unnamed-chunk-2_4da259879d3dedb035c5d5a8911cdb99'}\n\n```{.r .cell-code}\n# Fit Poisson model\ncmod1 <- glm(\n  count ~ text * expected,\n  data = LC19_T2, \n  family = poisson)\ncmod0 <- glm(\n  count ~ text + expected,\n  data = hecedsm::LC19_T2, \n  family = poisson)\n# Likelihood ratio test, chi-square (2) null\ncar::Anova(cmod1, type = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: count\n              LR Chisq Df Pr(>Chisq)    \ntext             0.182  1     0.6696    \nexpected        89.150  2     <2e-16 ***\ntext:expected   88.705  2     <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# Score test - the \"chi-squared test of independence\"\nanova(cmod0, cmod1, test = \"Rao\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel 1: count ~ text + expected\nModel 2: count ~ text * expected\n  Resid. Df Resid. Dev Df Deviance    Rao  Pr(>Chi)    \n1         8     96.372                                 \n2         6      7.667  2   88.705 81.071 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThe results of the likelihood ratio test and that of the score test are slightly different, but they test the same hypothesis. Here, we reject the null hypothesis of independence between text and expected: there is indeed an interaction present.\n\nThe results are somehow meaningless. First, one would need to check that there is no interaction between text and image before marginalizing, which is unlikely because part of the confusion would stem from inconsistent description along with the photo: if the display is a picture of six toothbrushes and the text description is 1 pack of 1, this is confusing. If the image agrees with the text, we expect people to answer correctly.\n\nRather than perform the test of @Lee.Choi:2019, the comparison of interest in my humble opinion is consistent (text one vs expected one has the same proportion as text 6 vs expected 6), and similarly for inconsistent. To test this, it suffices to permute entries and change the labels of the `expected`  factor.\n\n\n::: {#tbl-contingency2 .cell tbl-cap='Contingency table for null hypothesis of independence looking at the correspondance between text description and expectation of customers.' hash='counts_cache/html/tbl-contingency2_82845736a584cabd171668e5d4971302'}\n::: {.cell-output-display}\n|   | not sure| incorrect| correct|\n|:--|--------:|---------:|-------:|\n|1  |       10|        12|      81|\n|6  |       12|        17|      68|\n:::\n:::\n\n\nThe test statistic for this hypothesis is 2 with a $p$-value of 0.37. There is no evidence here that people have different levels of confusion if the text mentions a different quantity.\n\n\n## Study 2 - Bertrand and Mullainathan (2004)\n\nWhile by far the most common, there are more specialized hypothesis that can be considered with design. The following example showcases a test of symmetry for a square contingency table.\n\n\nWe consider a  study from @Bertrand.Mullainathan:2004, who study racial discrimination in hiring based on the consonance of applicants names. The authors created curriculum vitae for four applicants and randomly allocated them a name, either one typical of a white person or a black person. The response is a count indicating how many of the applicants were called back (out of two black and two white) depending on their origin.\n\nIf there was no racial discrimination (null hypothesis), we would expect the average number of times a white applicant was called back (but no black applicant) to be the same as a single black applicant (but no white). Only the entries for different numbers of call-back (either 0 vs 2, 0 vs 1 or 1 vs 2 for either race) are instructive about our question of interest. The data are reported in @tbl-contingencyMB.\n\n\n\n::: {#tbl-contingencyMB .cell tbl-cap='Contingency table for the racial discrimination in labor market.' hash='counts_cache/html/tbl-contingencyMB_398b4c3af34b64fd02c0c148f5211087'}\n::: {.cell-output-display}\n|   |   no| 1W| 2W|\n|:--|----:|--:|--:|\n|no | 1103| 74| 19|\n|1B |   33| 46| 18|\n|2B |    6|  7| 17|\n:::\n:::\n\n::: {.cell hash='counts_cache/html/unnamed-chunk-5_273d076938035db3399099090dc11df7'}\n\n:::\n\n\nThe hypothesis of symmetry postulates that the proportion on either side of the diagonal are the same, so $p_{ij}=p_{ji}$. Under the null hypothesis model, our best estimate of the proportion is thus $(n_{ij} + n_{ji})/2$, which is the sample average of those cells. The statistic is analogous to Fisher's goodness of fit test, except that the expected counts are estimated here. There are $J^2$ entries and we have $J(J-1)/2$ constraints (the degrees of freedom).\n\nThe test statistic reduces to \n$$X^2 = \\sum_{i,j} \\frac{(E_{ij}-O_{ij})^2}{E_{ij}} = \\sum_{j=1}^J \\frac{(n_{ij} - n_{ji})^2}{n_{ij}+n_{ji}}.$$ The statistic is 27.31, to be compared with a $\\chi^2_3$ benchmark (three off-diagonal entries). The $p$-value is $5\\times 10^{-6}$, highly suggestive of racial discrimination.\n\n\n::: {.cell hash='counts_cache/html/unnamed-chunk-6_54e059ed0f2ff1868b7298c19d91b1c6'}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}