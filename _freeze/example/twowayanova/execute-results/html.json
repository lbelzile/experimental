{
  "hash": "0f00d384aa91658c322ac1b3f34aa577",
  "result": {
    "markdown": "---\ntitle: \"Two-way analysis of variance\"\nlinktitle: \"Two-way ANOVA\"\ntype: docs\neditor_options: \n  chunk_output_type: console\nexecute:\n  \n  echo: true\n  eval: true\n  message: false\n  warning: false\n  cache: false\n  fig-align: 'center'\n  out-width: '80%'\n---\n\n\n\n\n# Videos\n\nThe **R** code [can be downloaded here](/example/twowayanova.R) and the [SPSS code here](/example/twoway.sps).\n\n\nThere's a set of videos that walks through each section below. To make it easier for you to jump around the video examples, I cut the long video into smaller pieces and included them all in [one YouTube playlist](https://www.youtube.com/playlist?list=PLUB8VZzxA8ItJKq70HCdYrRcsDUsJYKhb).\n\n- [ANOVA table](https://www.youtube.com/watch?v=pxQgRTWwITI&list=PLUB8VZzxA8ItJKq70HCdYrRcsDUsJYKhb)\n- [Interaction plot](https://www.youtube.com/watch?v=rYudu_vns6I&list=PLUB8VZzxA8ItJKq70HCdYrRcsDUsJYKhb)\n- [Contrasts and marginal means](https://www.youtube.com/watch?v=0ifni3rNOss&list=PLUB8VZzxA8ItJKq70HCdYrRcsDUsJYKhb)\n- [Effect size and power](https://www.youtube.com/watch?v=jcqpe3Z-YNs&list=PLUB8VZzxA8ItJKq70HCdYrRcsDUsJYKhb)\n- [SPSS walkthrough](https://www.youtube.com/watch?v=lxVJAzaBHyY&list=PLUB8VZzxA8ItJKq70HCdYrRcsDUsJYKhb)\n\nYou can also watch the playlist (and skip around to different sections) here:\n\n<div class=\"ratio ratio-16x9\">\n<iframe src=\"https://www.youtube.com/embed/playlist?list=PLUB8VZzxA8ItJKq70HCdYrRcsDUsJYKhb\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n</div>\n\n\n## Study 1 - balanced data\n\nWe consider data from a replication by Chandler (2016) of Study 4a of Janiszewski and Uy (2008). Both studies measured the amount of adjustment when presented with vague or precise range of value for objects, with potential encouragement for adjusting more the value.\n\n### Description\n\n@Chandler:2016 described the effect in the replication report:\n\n> Janiszewski and Uy (2008) conceptualized people’s attempt to adjust following presentation of an anchor as movement along a subjective representation scale by a certain number of units. Precise numbers (e.g. $9.99) imply a finer-resolution scale than round numbers (e.g. $10). Consequently, adjustment along a subjectively finer resolution scale will result in less objective adjustment than adjustment by the same number of units along a subjectively coarse resolution scale.\n\nThe experiment is a 2 by 2 factorial design (two-way ANOVA) with `anchor` (either round or precise) and `magnitude` (`0` for small, `1` for big adjustment) as experimental factors. A total of 120 students were recruited and randomly assigned to one of the four experimental sub-condition, for a total of 30 observations per subgroup (`anchor`, `magnitude`). The response variable is `majust`, the mean adjustment   for the price estimate of the item. The dataset is available from the **R** package `hecedsm` as `C16`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(dplyr)   # data manipulation\nlibrary(ggplot2) # graphics\nlibrary(emmeans) # contrasts, etc.\nlibrary(car) # companion to applied regression\n# Example of two-way ANOVA with balanced design\ndata(C16, package = \"hecedsm\")\n# Check for balance\nxtabs(formula = ~ anchor + magnitude,\n      data = C16)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         magnitude\nanchor     0  1\n  round   30 30\n  precise 30 30\n```\n:::\n:::\n\n\nWe can see that there are 30 observations in each group in the replication, as advertised.\n\n### Model fitting\n\n\nIn **R**, the function `aov` fits an analysis of variance model for *balanced data*. Analysis of variance are simple instances of linear regression models, and the main difference between fitting the model\nusing `aov` and `lm` is the default parametrization used. In more general settings (including continuous covariates), we will use `lm` as a workshorse to fit the model, with an option to set up the contrasts so the output matches our expectations (and needs).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit two-way ANOVA model\nmod <- aov(madjust ~ anchor * magnitude,\n           data = C16)\n# Analysis of variance table\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  Df Sum Sq Mean Sq F value   Pr(>F)    \nanchor             1  0.777   0.777   6.277   0.0136 *  \nmagnitude          1  8.796   8.796  71.058 1.09e-13 ***\nanchor:magnitude   1  0.002   0.002   0.013   0.9088    \nResiduals        116 14.359   0.124                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThe model is fitted as before by specifying the `response ~ explanatories`: the `*` notation is a shortcut to specify `anchor + magnitude + anchor:magnitude`, with the last term separated by a semi-colon `:` denoting an interaction between two variables. Here, the experimental factors `anchor` and `magnitude` are crossed, as it is possible to be in both experimental groups simultaneously.\n\n\n### Interaction plots\n\nThe `interaction.plot` function in base **R** allows one to create an interaction (or profile) plot for a two-way design. More generally, we can simply compute the group means for each combination of the experimental conditions, map the mean response to the $y$-axis of a graph and add the experimental factors to other dimensions ($x$-axis, panel, color, etc.) \n\n\n::: {.cell}\n\n```{.r .cell-code}\nC16 |>\n ggplot(mapping = aes(x = anchor,\n                      y = madjust,\n                      color = magnitude)) +\n  geom_jitter(width = 0.1,\n              alpha = 0.1) +\n  stat_summary(aes(group = magnitude), \n               fun = mean, \n               geom = \"line\") +\n  # Change position of labels\n  labs(y = \"\",\n       subtitle = \"Mean adjustment\") +\n  theme_classic() + # change theme\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](twowayanova_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nIn our example, the interaction plot shows a large main effect for `magnitude`, a smaller one for `anchor` and no evidence of interaction --- despite the uncertainty associated with the estimation, the lines are very close to being parallel. Overlaying the jitter observations shows there is quite a bit of spread, but with limited overlap. Despite the graphical evidence hinting that the interaction isn't significant, we will fit the two-way analysis of variance model with the interaction unless we invalidate our statistical inference.\n\nThe `emmip` function allows one to return a plot automagically.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Interaction plot\nemmeans::emmip(mod, \n               magnitude ~ anchor, \n               CIs = TRUE) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](twowayanova_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n### Estimated marginal means\n\nBecause our dataset is balanced, the marginal means (the summary statistics obtained by grouping the data for a single factor) and the marginal effects (obtained by calculating the average cell means by either row or column) will coincide. There are multiple functions that allow one to obtain estimates means for cells, rows or columns, including functionalities, notably `emmeans` from the eponymous package and `model.tables`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get grand mean, cell means, etc.\nmodel.tables(mod, type = \"means\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTables of means\nGrand mean\n            \n0.001155778 \n\n anchor \nanchor\n   round  precise \n 0.08162 -0.07931 \n\n magnitude \nmagnitude\n       0        1 \n-0.26959  0.27190 \n\n anchor:magnitude \n         magnitude\nanchor    0       1      \n  round   -0.1854  0.3487\n  precise -0.3537  0.1951\n```\n:::\n\n```{.r .cell-code}\n# Cell means\nemmeans(object = mod, \n        specs = c(\"anchor\", \"magnitude\"),\n        type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n anchor  magnitude emmean     SE  df lower.CL upper.CL\n round   0         -0.185 0.0642 116  -0.3127  -0.0582\n precise 0         -0.354 0.0642 116  -0.4810  -0.2265\n round   1          0.349 0.0642 116   0.2215   0.4759\n precise 1          0.195 0.0642 116   0.0679   0.3223\n\nConfidence level used: 0.95 \n```\n:::\n\n```{.r .cell-code}\n# Marginal means\nemmeans(object = mod, \n        specs = \"anchor\", \n        type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n anchor   emmean     SE  df lower.CL upper.CL\n round    0.0816 0.0454 116 -0.00834   0.1716\n precise -0.0793 0.0454 116 -0.16928   0.0107\n\nResults are averaged over the levels of: magnitude \nConfidence level used: 0.95 \n```\n:::\n\n```{.r .cell-code}\nemmeans(object = mod, \n        specs = \"anchor\", \n        type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n anchor   emmean     SE  df lower.CL upper.CL\n round    0.0816 0.0454 116 -0.00834   0.1716\n precise -0.0793 0.0454 116 -0.16928   0.0107\n\nResults are averaged over the levels of: magnitude \nConfidence level used: 0.95 \n```\n:::\n\n```{.r .cell-code}\n# These match summary statistics\nC16 |>\n  group_by(magnitude) |>\n  summarize(margmean = mean(madjust))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  magnitude margmean\n  <fct>        <dbl>\n1 0           -0.270\n2 1            0.272\n```\n:::\n\n```{.r .cell-code}\nC16 |>\n  group_by(anchor) |>\n  summarize(margmean = mean(madjust))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  anchor  margmean\n  <fct>      <dbl>\n1 round     0.0816\n2 precise  -0.0793\n```\n:::\n:::\n\n\nSince the data are balanced, we can look at the (default) analysis of variance table produced using\n`anova` function^[In general, for unbalanced data, one would use `car::Anova` with `type = 2` or `type = 3` effects.]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: madjust\n                  Df  Sum Sq Mean Sq F value    Pr(>F)    \nanchor             1  0.7770  0.7770  6.2768   0.01362 *  \nmagnitude          1  8.7962  8.7962 71.0584 1.089e-13 ***\nanchor:magnitude   1  0.0016  0.0016  0.0132   0.90879    \nResiduals        116 14.3595  0.1238                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThe output confirms our intuition that there is not much different from zero, with a strong effect for magnitude of adjustment and a significant, albeit smaller one, for anchor type.\n\n### Model assumptions\n\nWhile the conclusions are probably unambiguous due to the large evidence, it would be useful to check the model assumptions. \n\nThe sample size is just enough to forego normality checks, but the quantile-quantile plot can be useful to detect outliers and extremes. Outside of one potential value much lower than it's group mean, there is no cause for concern.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::qqPlot(mod, id = FALSE)\n```\n\n::: {.cell-output-display}\n![](twowayanova_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWith 30 observations per group and no appearance of outlier, we need rather to worry about additivity and possibly heterogeneity arising from the treatment. Independence is plausible based on the context.\n\nThe Tukey-Anscombe plot of residuals against fitted values (the group means) indicate no deviation, but the variance appears to be larger for the two groups with a large adjustment. Because the response takes negative values, we can simply proceed with fitting a two-way analysis in which each of the subgroups has mean $\\mu_{ij}$ and standard deviation $\\sigma_{ij}$: in other words, only the data for each subgroup (`anchor`, `magnitude`) are used to estimate the summary statistics of that group. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Evidence of unequal variance\nggplot(data = data.frame(residuals = resid(mod),\n                         fitted = fitted(mod)),\n       mapping = aes(x = fitted,\n                     y = residuals)) +\n   geom_jitter(width = 0.03, height = 0) +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](twowayanova_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Equality of variance - Brown-Forsythe\ncar::leveneTest(mod) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(>F)  \ngroup   3  2.8133 0.0424 *\n      116                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nGiven the Brown-Forsythe test output, we can try fitting a different variance in each group, as there are enough observations for this. The function `gls` in the `nlme` package fits such models; the weight argument being setup with a constant variance (`~1`) per each combination of the crossed factors `anchor * magnitude`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a variance per group\nmod2 <- nlme::gls(\n  model = madjust ~ anchor * magnitude,\n  data = C16,\n  weights = nlme::varIdent(\n    form = ~ 1 | anchor * magnitude))\n\n# Different ANOVA - we use type II here\ncar::Anova(mod2, type = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II tests)\n\nResponse: madjust\n                 Df   Chisq Pr(>Chisq)    \nanchor            1  6.7708   0.009266 ** \nmagnitude         1 79.9238  < 2.2e-16 ***\nanchor:magnitude  1  0.0132   0.908595    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nWe can see the unequal std. deviation per group when passing the model with unequal variance and unequal means and computing the estimated marginal means. The package `emmeans` automatically adjusts for these changes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans(object = mod2, \n        specs = c(\"anchor\", \"magnitude\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n anchor  magnitude emmean     SE   df lower.CL upper.CL\n round   0         -0.185 0.0676 29.1  -0.3236  -0.0473\n precise 0         -0.354 0.0422 29.0  -0.4401  -0.2674\n round   1          0.349 0.0796 29.0   0.1859   0.5115\n precise 1          0.195 0.0618 29.2   0.0688   0.3215\n\nDegrees-of-freedom method: satterthwaite \nConfidence level used: 0.95 \n```\n:::\n\n```{.r .cell-code}\n# Compute pairwise difference for anchor\nmarg_effect <- emmeans(object = mod2, \n        specs = \"anchor\") |> \n  pairs()\nmarg_effect\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast        estimate     SE  df t.ratio p.value\n round - precise    0.161 0.0642 100   2.505  0.0138\n\nResults are averaged over the levels of: magnitude \nDegrees-of-freedom method: satterthwaite \n```\n:::\n\n```{.r .cell-code}\n# To get a data frame with data\n# broom::tidy(marg_effect)\n```\n:::\n\n\n\nWe can then pass the output to `car::Anova` to print the analysis of variance table. The $p$-value for the main effect of `anchor` is 0.014 in the equal variance model. With unequal variance, different tests give different values: the $p$-value is 0.009 if we use type II effects (the correct choice here), 0.035 with type III effects^[The type 3 effects compare the model with interactions and main effects to one that includes the interaction, but removes the main effects. Not of interest in the present context.] and the `emmeans` package returns Welch's test for the pairwise difference with Satterwaite's degree of freedom approximation if we average over `magnitude` to account for the difference in variance, this time with a $p$-value of 0.014. These differences in output are somewhat notable: with *borderline statistical significance*, they may lead to different conclusions if one blindly dichotomize the results. Clearly stating which test and how the results are obtained is crucial for transparent reporting, as is providing the code and data. Let your readers make their own mind by reporting $p$-values.\n\n\n### Reporting\n\nRegardless of the model, it should be clearly stated that there is some evidence of heterogeneity. We should also report sample size per group, mention the repartition ($n=30$ per group).\n\nIn the present case, we can give information about the main effects and stop here, but giving an indication about the size of the adjustment (by reporting estimated marginal means) is useful. Note that `emmeans` gives a (here spurious) warning about the main effects (row or column average) since there is a potential interaction --- as we all but ruled out the latter, we proceed nevertheless.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemm_marg <- emmeans::emmeans(\n  object = mod2,\n  specs = \"anchor\"\n)\n```\n:::\n\n\nThere are many different options to get the same results with `emmeans`. The `specs` indicates the list of factors which we want to keep, whereas `by` gives the one we want to have separate analysis for. In formula, we could get the simple effects for `anchor` by level of `magnitude` using `~ anchor | magnitude`, or set `specs = anchor` and `by = magnitude`. We can  pass the result to `pairs` to obtain pairwise differences.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple effects for anchor\nemm_simple <- emmeans::emmeans(\n  object = mod,\n  specs = \"anchor\",\n  by = \"magnitude\"\n)\n# Compute pairwise differences within each magnitude\npairs(emm_simple)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nmagnitude = 0:\n contrast        estimate     SE  df t.ratio p.value\n round - precise    0.168 0.0908 116   1.853  0.0665\n\nmagnitude = 1:\n contrast        estimate     SE  df t.ratio p.value\n round - precise    0.154 0.0908 116   1.690  0.0936\n```\n:::\n:::\n\n\n### Multiplicity adjustment\n\nBy default, `emmeans` will compute adjustments for pairwise difference using Tukey's honest significant difference method if there are more than one pairwise comparison. The software cannot easily guess the degrees of freedom, the number of tests, etc.\n\nThere are also tests which are not of interest: for example, one probably wouldn't want to compute the difference between the adjustment for (small magnitude and round) versus (large magnitude and precise).\n\nIf we were interested in looking at all pairwise differences, we could keep all of the cells means.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans(object = mod2, \n        specs = c(\"magnitude\", \"anchor\"), \n        contr = \"pairwise\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$emmeans\n magnitude anchor  emmean     SE   df lower.CL upper.CL\n 0         round   -0.185 0.0676 29.1  -0.3236  -0.0473\n 1         round    0.349 0.0796 29.0   0.1859   0.5115\n 0         precise -0.354 0.0422 29.0  -0.4401  -0.2674\n 1         precise  0.195 0.0618 29.2   0.0688   0.3215\n\nDegrees-of-freedom method: satterthwaite \nConfidence level used: 0.95 \n\n$contrasts\n contrast                                estimate     SE   df t.ratio p.value\n magnitude0 round - magnitude1 round       -0.534 0.1044 56.7  -5.115  <.0001\n magnitude0 round - magnitude0 precise      0.168 0.0797 48.7   2.112  0.1636\n magnitude0 round - magnitude1 precise     -0.381 0.0916 57.6  -4.156  0.0006\n magnitude1 round - magnitude0 precise      0.702 0.0901 44.2   7.795  <.0001\n magnitude1 round - magnitude1 precise      0.154 0.1008 54.6   1.524  0.4306\n magnitude0 precise - magnitude1 precise   -0.549 0.0748 51.5  -7.333  <.0001\n\nDegrees-of-freedom method: satterthwaite \nP value adjustment: tukey method for comparing a family of 4 estimates \n```\n:::\n:::\n\n\nNotice now the mention about Tukey's effect. When there is heterogeneity of variance or unbalanced effects, the actual method employed is called **Games-Howell** correction.\n\n\n## Study 2 - unbalanced data\n\n\nWe now reproduce the results of Study 1 of @Maglio/Polman:2014. Data were obtained from the Open Science Foundation and are available in the `MP14_S1` dataset in package `hecedsm`.\n\n> We carried out a 2 (orientation: toward, away from) × 4 (station: Spadina, St. George, Bloor-Yonge, Sherbourne) analysis of variance (ANOVA) on closeness ratings.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(MP14_S1, package = \"hecedsm\")\nxtabs(~ direction + station, data = MP14_S1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         station\ndirection Spadina St. George Bloor-Yonge Sherbourne\n     east      26         26          23         26\n     west      25         25          26         25\n```\n:::\n:::\n\n\nThe counts are not balanced, but not far from being equal in each group.\n\nBased on the actual study, it is quite clear we expect there will be an interaction if there is an actual effect. Lack of interaction would entail that subjective distance is perceived the same way regardless of the direction of travel. \n\n### Model assumptions\n\nSince the data are unbalanced, we can fit the model using `lm`. The default parametrization of the linear model uses the first alphanumerical value for the factor as reference category and coefficients encode differences relative to this particular average. We can obtain the sum-to-zero by setting the option `contr.sum`^[The second term specifies the default option for continuous variables.]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(MP14_S1) # look at data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntibble [202 × 3] (S3: tbl_df/tbl/data.frame)\n $ station  : Factor w/ 4 levels \"Spadina\",\"St. George\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ direction: Factor w/ 2 levels \"east\",\"west\": 1 1 1 1 1 1 1 1 1 1 ...\n $ distance : int [1:202] 1 2 2 3 1 1 2 1 3 2 ...\n```\n:::\n\n```{.r .cell-code}\n# Set up contrasts\noptions(contrasts = c(\"contr.sum\", \"contr.poly\"))\nmodel <- lm(distance ~ station*direction, \n            data = MP14_S1)\nsummary(model) # the coefficients are global mean\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = distance ~ station * direction, data = MP14_S1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6538 -0.6400  0.1154  0.3913  2.8077 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          2.65916    0.07294  36.458  < 2e-16 ***\nstation1             0.48776    0.12587   3.875 0.000146 ***\nstation2            -0.45455    0.12587  -3.611 0.000388 ***\nstation3            -0.75866    0.12771  -5.941 1.29e-08 ***\ndirection1           0.04109    0.07294   0.563 0.573870    \nstation1:direction1  0.46584    0.12587   3.701 0.000280 ***\nstation2:direction1  0.52353    0.12587   4.159 4.79e-05 ***\nstation3:direction1 -0.33289    0.12771  -2.607 0.009853 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.036 on 194 degrees of freedom\nMultiple R-squared:  0.3813,\tAdjusted R-squared:  0.359 \nF-statistic: 17.08 on 7 and 194 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# Test only the interaction\ncar::Anova(model, type = 3) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type III tests)\n\nResponse: distance\n                   Sum Sq  Df   F value    Pr(>F)    \n(Intercept)       1426.15   1 1329.1917 < 2.2e-16 ***\nstation             77.58   3   24.1005 2.665e-13 ***\ndirection            0.34   1    0.3173    0.5739    \nstation:direction   52.41   3   16.2832 1.765e-09 ***\nResiduals          208.15 194                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n### Model assumptions\n\nWe can use type II or type III tests: here, because the interaction term is significant, we could look at simple effects but these are not of scientific interest. Rather, we compute the cell averages and proceed with our contrast setup.\n\nBecause of the discreteness of the data (a Likert scale ranging from 1 to 5), there is limited potential for outlyingness. If you look at the normal quantile-quantile plot, you should see a marked staircase pattern due to the ties. Brown--Forsythe's test gives no evidence of unequal variance per group, so we proceed with the model.\n\n### Interaction plot\n\nWhile we can do plots ourselves, the `emmip` function allows us to return a nice looking profile plot with `ggplot2`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans::emmip(object = model, \n               # trace.factor ~ x.factor\n               formula = direction ~ station,\n               CIs = TRUE) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](twowayanova_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Interaction plot \n# average of each subgroup, with +/- 1 std. error\n\nMP14_S1 |>\n  group_by(direction, station) |>\n  summarize(mean = mean(distance),\n            se = sigma(model) / sqrt(n()),\n            lower = mean - se,\n            upper = mean + se) |>\n  ggplot(mapping = aes(x = station,\n                       y = mean, \n                       group = direction,\n                       col = direction)) + \n  geom_line() +\n  geom_errorbar(aes(ymin = lower, \n                    ymax = upper),\n                width = 0.2) +\n  geom_point() +\n  scale_colour_grey() +\n  labs(title = \"subjective distance\",\n       subtitle = \"mean (1 std. error)\",\n       x = \"subway station\",\n       y = \"\",\n       caption = \"stations are ordered from west to east\") +\n  theme_classic() +\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](twowayanova_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n### Contrasts\n\nIf the data lend some support for this claim, we could consider the following follow-up questions:\n\n- symmetry\n- whether the average perceived distance for St. George (east) and Bloor--Yonge (west) is the same as vice-versa (both one station away from Bay).\n- same, but for Spadina and Sherbourne which are two stations away from Bay.\n- if the perceived distance for stations Spadina or Sherbourne, which are two away from Bay, are viewed as being twice as distance as St. George and Bloor--Yonge.\n\nFor the experiment to make sense, we should check that travel time or distance is indeed roughly the same between each station. These hypotheses can be expressed in terms of contrasts.\n\nIn `emmeans`, we keep both factors in the model and begin by computing the cell means and looking at the order of the factors and ordering of the levels to properly set our contrast vectors.\n\n\nThe hypothesis of symmetry is slightly complicated, as we want to test a model which has the same perceived distance for distance, but comparing stations one apart and two apart in the same direction of travel. This leads to four contrast vectors, but we set up the hypothesis test to look at them simultaneously using an $F$-test. If we impose same mean perceived distance for each station with the symmetry, we would have four average instead of the eight cells: the null distribution for the mean comparison will be a Fisher distribution with $\\nu_1=8-4=4$ degrees of freedom.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemm <- emmeans(model, \n               specs = c(\"direction\", \"station\"))\nlevels(emm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$direction\n[1] \"east\" \"west\"\n\n$station\n[1] \"Spadina\"     \"St. George\"  \"Bloor-Yonge\" \"Sherbourne\" \n```\n:::\n\n```{.r .cell-code}\ncontrast_list <- list(\n \"2 station (opposite)\" = c(1, 0, 0, 0, 0, 0, 0, -1),\n \"1 station (opposite)\" = c(0, 0, 1, 0, 0, -1, 0, 0),\n \"2 station (travel)\" = c(0, 1, 0, 0, 0, 0, -1, 0),\n \"1 station (travel)\" = c(0, 0, 0, 1, -1, 0, 0, 0)\n)\n# Hypothesis test (symmetry)\nemm |> \n  contrast(method = contrast_list) |> \n  test(joint = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n df1 df2 F.ratio p.value\n   4 194   1.416  0.2300\n```\n:::\n:::\n\n\nPerhaps unsurprisingly, there is not much difference and we cannot detect departure from symmetry.\n\nThe other hypothesis tests, which look at perceived differences one direction or another, quantify the difference in subjective distance depending on whether the station is in the direction of travel or opposite.\n\n\\begin{align*}\n\\mathscr{H}_{01} &: \\mu_{\\text{E, SG}} + \\mu_{\\text{W, BY}} = \\mu_{\\text{W, SG}} +\\mu_{\\text{E, BY}} \\\\\n\\mathscr{H}_{02} &: \\mu_{\\text{E, Sp}} +\\mu_{\\text{W, Sh}} = \\mu_{\\text{W, Sp}} + \\mu_{\\text{E, Sh}} \\\\\n\\mathscr{H}_{03} &: 2(\\mu_{\\text{E, SG}} + \\mu_{\\text{W, BY}}) = \\mu_{\\text{E, Sp}} + \\mu_{\\text{W, Sh}} \\\\\n\\mathscr{H}_{04} &: 2(\\mu_{\\text{W, SG}} + \\mu_{\\text{E, BY}}) = \\mu_{\\text{W, Sp}} + \\mu_{\\text{E, Sh}} \n\\end{align*}\n\nHypotheses 3 and 4 could be tested jointly, using the same trick we employed for symmetry to impose the linear restrictions on the parameters. We will consider only the pairwise differences in the sequel.\n\nSince we consider arbitrary contrasts between the means of the eight cells, we can account for multiple testing within the family by using Scheffé's method. In `emmeans`, the `adjust = \"scheffe\"` argument sets up the contrasts, but the output will be incorrect unless we specify the number of groups (for main effects, $n_a-1$, for all cells, $n_an_b-1$) through `scheffe.rank`.\n\nTo account for the other tests, we can also reduce the level to decrease the probability of making a type I error.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustom_contrasts <- list(\n \"2 station, opposite vs same\" = \n   c(1, -1, 0, 0, 0, 0, -1, 1),\n \"1 station, opposite vs same\" = \n   c(0, 0, 1, -1, -1, 1, 0, 0),\n \"1 vs 2 station (opposite)\" = \n   c(-1, 0, 2, 0, 0, 2, 0, -1),\n \"1 vs 2 station (same)\" = \n   c(0, -1, 0, 2, 2, 0, -1, 0)\n)\n# Set up contrasts with correction\ncont_emm <- contrast(\n  object = emm, \n  method = custom_contrasts,\n  adjust = \"scheffe\")\n# Tests and p-values\ncont_emm |>\n  test(scheffe.rank = 7)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast                    estimate    SE  df t.ratio p.value\n 2 station, opposite vs same     2.24 0.410 194   5.470  0.0002\n 1 station, opposite vs same     1.71 0.415 194   4.129  0.0206\n 1 vs 2 station (opposite)       2.27 0.644 194   3.525  0.0942\n 1 vs 2 station (same)           1.09 0.665 194   1.636  0.9120\n\nP value adjustment: scheffe method with rank 7 \n```\n:::\n\n```{.r .cell-code}\n# Tests with confidence intervals\ncont_emm |>\n  confint(scheffe.rank = 7,\n          level = 0.99)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast                    estimate    SE  df lower.CL upper.CL\n 2 station, opposite vs same     2.24 0.410 194    0.450     4.04\n 1 station, opposite vs same     1.71 0.415 194   -0.102     3.53\n 1 vs 2 station (opposite)       2.27 0.644 194   -0.546     5.08\n 1 vs 2 station (same)           1.09 0.665 194   -1.821     4.00\n\nConfidence level used: 0.99 \nConf-level adjustment: scheffe method with rank 7 \n```\n:::\n:::\n\n\nEven with a correction for multiple testing, there is strong difference in perceived distance for one station away (direction of travel vs opposite) and similarly for two stations. There is mild evidence that, in one direction, the perceived distance between stations is not equal. A potential criticism, in addition to the design of the scale, would be about real distance between stations may not be the same.\n\n\n::: {.cell}\n\n:::\n\n\n## References\n",
    "supporting": [
      "twowayanova_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}